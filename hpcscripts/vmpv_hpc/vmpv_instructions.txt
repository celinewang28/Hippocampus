This program assumes the following has been done:
	1. Skeletal directories have been set up according to "Using OSort" in Hippocampus Code"
	2. Matlab path for hippocampus files has been set up on hpc
	3. rplparallel.mat, binData.hdf, umaze.mat are in session directories

Save the list of sessions to be processed in this (Hippocampus/vmpv_hpc) folder as sessions.txt, separated by newline, see example:
	/volume1/Hippocampus/Data/picasso-misc/20181105/session01
	/volume1/Hippocampus/Data/picasso-misc/20181101/session01 
(There must be a newline after the last line, or all entries after the first will not be read.)

Check pvsubmit.pbs, ensure that the following parameters are ok:
	queue (eg. openmp, serial. Recommend "short" for faster queues but memory limit might be a problem)
	number of cpus (suggested 5, depends on queue)
	memory (suggested 15GB for 1px, depends on raycasting radius)

Files will be sequentially transferred in and passed as jobs with the command:
	sh pvhpc.sh

For some reason (probably to do with the hpc's firewall) the completed files cannot be scp'd back into the hippocampus drive. They have to be manually transferred out once the jobs are finished.
